{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhrNMxIuhavDwBVP7kqOve",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krupavainala/ML_23AG1A66I9/blob/main/NLP_lab_programs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKF3Kr0-qAy-",
        "outputId": "adbf427b-ae74-481c-950e-1fd61e0bdf5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Hello! This is a simple example, and it works without libraries.\n",
            "Tokens: ['Hello', 'This', 'is', 'a', 'simple', 'example', 'and', 'it', 'works', 'without', 'libraries']\n",
            "StopWords: ['Hello', 'simple', 'example', 'works', 'without', 'libraries']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\,'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\,'\n",
            "/tmp/ipython-input-3801250740.py:3: SyntaxWarning: invalid escape sequence '\\,'\n",
            "  punctuation_marks = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n"
          ]
        }
      ],
      "source": [
        "text = \"Hello! This is a simple example, and it works without libraries.\"\n",
        "stop_words = [\"is\", \"a\", \"and\", \"it\", \"the\", \"this\", \"to\", \"of\"]\n",
        "punctuation_marks = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "clean_text = \"\"\n",
        "for char in text:\n",
        "  if char not in punctuation_marks:\n",
        "    clean_text += char\n",
        "tokens = clean_text.split()\n",
        "filtered_tokens = []\n",
        "for word in tokens:\n",
        "  if word.lower() not in stop_words:\n",
        "    filtered_tokens.append(word)\n",
        "print(f\"Original Text: {text}\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"StopWords: {filtered_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxj2Wg-or4u6",
        "outputId": "e5dbeb65-872b-49dd-eb7d-c12f0deb5bc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"balayya is not a name, it is an emotion. Jai balayya\"\n",
        "words=word_tokenize (sentence)\n",
        "word='emotion'\n",
        "sense=lesk (words, word)\n",
        "if sense:\n",
        "  print (f\"best sense for '(word)': {sense.name()}\")\n",
        "  print(f\"definition: {sense.definition()}\")\n",
        "else:\n",
        "  print(f\"no sense found for '{word}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CipALN28vCzL",
        "outputId": "9d3b1c7e-256b-42d3-8492-4fe6f5e476a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best sense for '(word)': emotion.n.01\n",
            "definition: any strong feeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "ps = PorterStemmer()\n",
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmed\"]\n",
        "print(\"Converting Word to its Stem\")\n",
        "print(\"-\" * 30)\n",
        "for w in words:\n",
        "    print(f\"{w} --> {ps.stem(w)}\")\n",
        "sentence = \"The programmers are programming a new program in Python\"\n",
        "tokenized_words = nltk.word_tokenize(sentence)\n",
        "print(\"\\nSentence Stemming:\")\n",
        "stemmed_sentence = [ps.stem(w) for w in tokenized_words]\n",
        "print(\" \".join(stemmed_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wixBIMSavYtE",
        "outputId": "04a1873e-8af8-4044-c3a7-330946cdf4a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting Word to its Stem\n",
            "------------------------------\n",
            "program --> program\n",
            "programs --> program\n",
            "programmer --> programm\n",
            "programming --> program\n",
            "programmed --> program\n",
            "\n",
            "Sentence Stemming:\n",
            "the programm are program a new program in python\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_dict = {\n",
        "    \"cat\": \"NOUN\",\n",
        "    \"dog\": \"NOUN\",\n",
        "    \"child\": \"NOUN\",\n",
        "    \"run\": \"VERB\",\n",
        "    \"eat\": \"VERB\",\n",
        "    \"play\": \"VERB\",\n",
        "    \"happy\": \"ADJECTIVE\",\n",
        "    \"blue\": \"ADJECTIVE\",\n",
        "    \"i\": \"PRONOUN\",\n",
        "    \"you\": \"PRONOUN\"\n",
        "}\n",
        "word = input().lower()\n",
        "\n",
        "if word in pos_dict:\n",
        "    print(pos_dict[word])\n",
        "else:\n",
        "    print(\"UNKNOWN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGAnoPG26jtz",
        "outputId": "2b0a69ea-27ed-4d1e-c2a2-9fa0cea10a3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n",
            "NOUN\n"
          ]
        }
      ]
    }
  ]
}